# Import required libraries
import requests
from bs4 import BeautifulSoup
import pandas as pd

# Target URL for Data Engineer jobs
url = "https://remoteok.com/remote-data-engineer-jobs"

# Headers to mimic a browser request
headers = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 "
                  "(KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36"
}

# Fetch the HTML content from the website
response = requests.get(url, headers=headers)

# Check if the request was successful
if response.status_code != 200:
    print(f"Failed to retrieve page. Status code: {response.status_code}")
else:
    # Parse the HTML with BeautifulSoup
    soup = BeautifulSoup(response.text, "html.parser")

    # List to store job details
    jobs = []

    # Loop through all job rows
    for job_row in soup.find_all("tr", class_="job"):
        title_tag = job_row.find("h2", itemprop="title")
        company_tag = job_row.find("h3", itemprop="name")
        location_tag = job_row.find("div", class_="location")
        link_tag = job_row.find("a", class_="preventLink")

        # Only append if title, company, and link exist
        if title_tag and company_tag and link_tag:
            job_info = {
                "Title": title_tag.text.strip(),
                "Company": company_tag.text.strip(),
                "Location": location_tag.text.strip() if location_tag else "Not specified",
                "Link": "https://remoteok.com" + link_tag["href"]
            }
            jobs.append(job_info)

    # Convert job list to a DataFrame
    df = pd.DataFrame(jobs)

    # Display first few results
    print(df.head())

    # Display total number of jobs scraped
    print(f"\nTotal jobs scraped: {len(df)}")
